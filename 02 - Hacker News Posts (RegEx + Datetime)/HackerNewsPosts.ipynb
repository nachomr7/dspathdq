{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Posts\n",
    "\n",
    "In this project we'll work with data of posts from [Hacker News](https://news.ycombinator.com/), a popular site where technology related stories (or 'posts') are voted and commented on.\n",
    "\n",
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. Likewise, users submit `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "## Opening the data\n",
    "\n",
    "We'll start by opening the data set, read it line by line and displaying the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "file = open('hacker_news.csv')\n",
    "read = reader(file)\n",
    "hn = list(read)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data\n",
    "\n",
    "Now we'll filter our data in order to separate the posts whose titles start with `Ask HN` or `Show HN` as we mentioned previously. To do this we'll use regular expressions to create 3 lists that contain the `Ask` posts, the `Show` posts and the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744 Ask posts, corresponding to the 8.68% of the total posts\n",
      "1162 Show posts, corresponding to the 5.78% of the total posts\n",
      "17194 Other posts, corresponding to the 85.54% of the total posts\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    match1 = re.search(r\"^Ask HN\",title,re.I)\n",
    "    match2 = re.search(r\"^Show HN\",title,re.I)\n",
    "    if match1:\n",
    "        ask_posts.append(row)\n",
    "    elif match2:\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "ask_percentage = round((len(ask_posts)/len(hn))*100,2)\n",
    "show_percentage = round((len(show_posts)/len(hn))*100,2)\n",
    "other_percentage = round((len(other_posts)/len(hn))*100,2)\n",
    "        \n",
    "print(len(ask_posts),'Ask posts, corresponding to the',str(ask_percentage)+'%','of the total posts')\n",
    "print(len(show_posts),'Show posts, corresponding to the',str(show_percentage)+'%','of the total posts')\n",
    "print(len(other_posts),'Other posts, corresponding to the',str(other_percentage)+'%','of the total posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data\n",
    "\n",
    "Moving on we'll be working with the number of comments, contained in the `num_comments` column, each type of post has so we can compare them based on this criteria. For this matter we'll use list comprehension to extract these values and then compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask posts have 14.038 comments on average\n",
      "Show posts have 10.317 comments on average\n"
     ]
    }
   ],
   "source": [
    "ask_comments = [int(row[4]) for row in ask_posts]\n",
    "show_comments = [int(row[4]) for row in show_posts]\n",
    "\n",
    "avg_ask_comments = sum(ask_comments)/len(ask_comments)\n",
    "avg_show_comments = sum(show_comments)/len(show_comments)\n",
    "\n",
    "print('Ask posts have',round(avg_ask_comments,2),'comments on average')\n",
    "print('Show posts have',round(avg_show_comments,2),'comments on average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe `Ask` posts have more comments on average than `Show` posts, averaging around 36% more comments. From now on we'll focus only on the `Ask` posts and dig a bit deeper on information about these posts. With the help of the `datetime` module we'll be analyzing how the time they were posted impacts how many comments they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.578], ['13', 14.741], ['10', 13.441], ['14', 13.234], ['16', 16.796], ['23', 7.985], ['12', 9.411], ['17', 11.46], ['15', 38.595], ['21', 16.009], ['20', 21.525], ['02', 23.81], ['18', 13.202], ['03', 7.796], ['05', 10.087], ['19', 10.8], ['01', 11.383], ['22', 6.746], ['08', 10.25], ['04', 7.17], ['00', 8.127], ['06', 9.023], ['07', 7.853], ['11', 11.052]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "created_date = [row[6] for row in ask_posts]\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "result_list = zip(created_date,ask_comments)\n",
    "\n",
    "for date,comment in result_list:\n",
    "    date_dt = dt.datetime.strptime(date,'%m/%d/%Y %H:%M')\n",
    "    hour = date_dt.strftime('%H')\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "        \n",
    "avg_by_hour = [[i,round(comments_by_hour[i]/counts_by_hour[i],2)] for i in comments_by_hour]\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "\n",
    "We were able to obtain the average number of comments per post by the hour of the day, but the list looks a bit messy so we'll sort it to get the values in a more clean presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments:\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = sorted(avg_by_hour,key=lambda row:row[1],reverse=True)\n",
    "print('Top 5 Hours for \\'Ask HN\\' Comments:\\n')\n",
    "for couple in avg_by_hour[:5]:\n",
    "    hour = dt.datetime.strptime(couple[0],'%H')\n",
    "    hour = hour.strftime('%H:%M')\n",
    "    print(\"{}: {:.2f} average comments per post\".format(hour,couple[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed in the table above, the most popular hours are after lunch (15-16hrs), after dinner (20-21hrs) and the early morning (2AM). The common denominator here is they all belong to hours when people is resting or not very productive so they have more time to spare and check some posts in the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
